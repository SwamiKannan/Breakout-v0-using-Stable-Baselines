# PPO with 20000 steps

## Reference
[Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1312.5602)

## Parameters
Default parameters as per [Stable Baselines](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)

## Performance logs
![Trained model](https://github.com/SwamiKannan/Reinforcement-Learning/blob/main/Stable%20baselines/Breakout-v0/PPO_200000/logs/tensorboard.png)

## Renders
1. Random <br>
![Random agent](https://github.com/SwamiKannan/Reinforcement-Learning/blob/main/Stable%20baselines/Breakout-v0/PPO_200000/render/random.gif)

2. Modelled <br>
![Modelled agent](https://github.com/SwamiKannan/Reinforcement-Learning/blob/main/Stable%20baselines/Breakout-v0/PPO_200000/render/Modelled.gif)
